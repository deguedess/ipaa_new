{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Author: Gael Varoquaux gael.varoquaux@normalesup.org\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import cluster, covariance, manifold\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Retrieve the data from Internet\n",
    "\n",
    "# The data is from 2003 - 2008. This is reasonably calm: (not too long ago so\n",
    "# that we get high-tech firms, and before the 2008 crash). This kind of\n",
    "# historical data can be obtained for from APIs like the quandl.com and\n",
    "# alphavantage.co ones.\n",
    "\n",
    "symbol_dict = {\n",
    "    \"TOT\": \"Total\",\n",
    "    \"XOM\": \"Exxon\",\n",
    "    \"CVX\": \"Chevron\",\n",
    "    \"COP\": \"ConocoPhillips\",\n",
    "    \"VLO\": \"Valero Energy\",\n",
    "    \"MSFT\": \"Microsoft\",\n",
    "    \"IBM\": \"IBM\",\n",
    "    \"TWX\": \"Time Warner\",\n",
    "    \"CMCSA\": \"Comcast\",\n",
    "    \"CVC\": \"Cablevision\",\n",
    "    \"YHOO\": \"Yahoo\",\n",
    "    \"DELL\": \"Dell\",\n",
    "    \"HPQ\": \"HP\",\n",
    "    \"AMZN\": \"Amazon\",\n",
    "    \"TM\": \"Toyota\",\n",
    "    \"CAJ\": \"Canon\",\n",
    "    \"SNE\": \"Sony\",\n",
    "    \"F\": \"Ford\",\n",
    "    \"HMC\": \"Honda\",\n",
    "    \"NAV\": \"Navistar\",\n",
    "    \"NOC\": \"Northrop Grumman\",\n",
    "    \"BA\": \"Boeing\",\n",
    "    \"KO\": \"Coca Cola\",\n",
    "    \"MMM\": \"3M\",\n",
    "    \"MCD\": \"McDonald's\",\n",
    "    \"PEP\": \"Pepsi\",\n",
    "    \"K\": \"Kellogg\",\n",
    "    \"UN\": \"Unilever\",\n",
    "    \"MAR\": \"Marriott\",\n",
    "    \"PG\": \"Procter Gamble\",\n",
    "    \"CL\": \"Colgate-Palmolive\",\n",
    "    \"GE\": \"General Electrics\",\n",
    "    \"WFC\": \"Wells Fargo\",\n",
    "    \"JPM\": \"JPMorgan Chase\",\n",
    "    \"AIG\": \"AIG\",\n",
    "    \"AXP\": \"American express\",\n",
    "    \"BAC\": \"Bank of America\",\n",
    "    \"GS\": \"Goldman Sachs\",\n",
    "    \"AAPL\": \"Apple\",\n",
    "    \"SAP\": \"SAP\",\n",
    "    \"CSCO\": \"Cisco\",\n",
    "    \"TXN\": \"Texas Instruments\",\n",
    "    \"XRX\": \"Xerox\",\n",
    "    \"WMT\": \"Wal-Mart\",\n",
    "    \"HD\": \"Home Depot\",\n",
    "    \"GSK\": \"GlaxoSmithKline\",\n",
    "    \"PFE\": \"Pfizer\",\n",
    "    \"SNY\": \"Sanofi-Aventis\",\n",
    "    \"NVS\": \"Novartis\",\n",
    "    \"KMB\": \"Kimberly-Clark\",\n",
    "    \"R\": \"Ryder\",\n",
    "    \"GD\": \"General Dynamics\",\n",
    "    \"RTN\": \"Raytheon\",\n",
    "    \"CVS\": \"CVS\",\n",
    "    \"CAT\": \"Caterpillar\",\n",
    "    \"DD\": \"DuPont de Nemours\",\n",
    "}\n",
    "\n",
    "\n",
    "symbols, names = np.array(sorted(symbol_dict.items())).T\n",
    "\n",
    "quotes = []\n",
    "\n",
    "for symbol in symbols:\n",
    "   # print(\"Fetching quote history for %r\" % symbol, file=sys.stderr)\n",
    "    url = (\n",
    "        \"https://raw.githubusercontent.com/scikit-learn/examples-data/\"\n",
    "        \"master/financial-data/{}.csv\"\n",
    "    )\n",
    "    quotes.append(pd.read_csv(url.format(symbol)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "close_prices = np.vstack([q[\"close\"] for q in quotes])\n",
    "open_prices = np.vstack([q[\"open\"] for q in quotes])\n",
    "\n",
    "# The daily variations of the quotes are what carry most information\n",
    "variation = close_prices - open_prices\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Learn a graphical structure from the correlations\n",
    "edge_model = covariance.GraphicalLassoCV()\n",
    "\n",
    "# standardize the time series: using correlations rather than covariance\n",
    "# is more efficient for structure recovery\n",
    "X = variation.copy().T\n",
    "X /= X.std(axis=0)\n",
    "edge_model.fit(X)\n",
    "\n",
    "# #############################################################################\n",
    "# Cluster using affinity propagation\n",
    "\n",
    "_, labels = cluster.affinity_propagation(edge_model.covariance_, random_state=0)\n",
    "n_labels = labels.max()\n",
    "\n",
    "for i in range(n_labels + 1):\n",
    "    print(\"Cluster %i: %s\" % ((i + 1), \", \".join(names[labels == i])))\n",
    "\n",
    "# #############################################################################\n",
    "# Find a low-dimension embedding for visualization: find the best position of\n",
    "# the nodes (the stocks) on a 2D plane\n",
    "\n",
    "# We use a dense eigen_solver to achieve reproducibility (arpack is\n",
    "# initiated with random vectors that we don't control). In addition, we\n",
    "# use a large number of neighbors to capture the large-scale structure.\n",
    "node_position_model = manifold.LocallyLinearEmbedding(\n",
    "    n_components=2, eigen_solver=\"dense\", n_neighbors=6\n",
    ")\n",
    "\n",
    "embedding = node_position_model.fit_transform(X.T).T\n",
    "\n",
    "# #############################################################################\n",
    "# Visualization\n",
    "plt.figure(1, facecolor=\"w\", figsize=(10, 8))\n",
    "plt.clf()\n",
    "ax = plt.axes([0.0, 0.0, 1.0, 1.0])\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Display a graph of the partial correlations\n",
    "partial_correlations = edge_model.precision_.copy()\n",
    "d = 1 / np.sqrt(np.diag(partial_correlations))\n",
    "partial_correlations *= d\n",
    "partial_correlations *= d[:, np.newaxis]\n",
    "non_zero = np.abs(np.triu(partial_correlations, k=1)) > 0.02\n",
    "\n",
    "# Plot the nodes using the coordinates of our embedding\n",
    "plt.scatter(\n",
    "    embedding[0], embedding[1], s=100 * d ** 2, c=labels, cmap=plt.cm.nipy_spectral\n",
    ")\n",
    "\n",
    "# Plot the edges\n",
    "start_idx, end_idx = np.where(non_zero)\n",
    "# a sequence of (*line0*, *line1*, *line2*), where::\n",
    "#            linen = (x0, y0), (x1, y1), ... (xm, ym)\n",
    "segments = [\n",
    "    [embedding[:, start], embedding[:, stop]] for start, stop in zip(start_idx, end_idx)\n",
    "]\n",
    "values = np.abs(partial_correlations[non_zero])\n",
    "lc = LineCollection(\n",
    "    segments, zorder=0, cmap=plt.cm.hot_r, norm=plt.Normalize(0, 0.7 * values.max())\n",
    ")\n",
    "lc.set_array(values)\n",
    "lc.set_linewidths(15 * values)\n",
    "ax.add_collection(lc)\n",
    "\n",
    "# Add a label to each node. The challenge here is that we want to\n",
    "# position the labels to avoid overlap with other labels\n",
    "for index, (name, label, (x, y)) in enumerate(zip(names, labels, embedding.T)):\n",
    "\n",
    "    dx = x - embedding[0]\n",
    "    dx[index] = 1\n",
    "    dy = y - embedding[1]\n",
    "    dy[index] = 1\n",
    "    this_dx = dx[np.argmin(np.abs(dy))]\n",
    "    this_dy = dy[np.argmin(np.abs(dx))]\n",
    "    if this_dx > 0:\n",
    "        horizontalalignment = \"left\"\n",
    "        x = x + 0.002\n",
    "    else:\n",
    "        horizontalalignment = \"right\"\n",
    "        x = x - 0.002\n",
    "    if this_dy > 0:\n",
    "        verticalalignment = \"bottom\"\n",
    "        y = y + 0.002\n",
    "    else:\n",
    "        verticalalignment = \"top\"\n",
    "        y = y - 0.002\n",
    "    plt.text(\n",
    "        x,\n",
    "        y,\n",
    "        name,\n",
    "        size=10,\n",
    "        horizontalalignment=horizontalalignment,\n",
    "        verticalalignment=verticalalignment,\n",
    "        bbox=dict(\n",
    "            facecolor=\"w\",\n",
    "            edgecolor=plt.cm.nipy_spectral(label / float(n_labels)),\n",
    "            alpha=0.6,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "plt.xlim(\n",
    "    embedding[0].min() - 0.15 * embedding[0].ptp(),\n",
    "    embedding[0].max() + 0.10 * embedding[0].ptp(),\n",
    ")\n",
    "plt.ylim(\n",
    "    embedding[1].min() - 0.03 * embedding[1].ptp(),\n",
    "    embedding[1].max() + 0.03 * embedding[1].ptp(),\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1242652e4d1e1d4e3bb6033bda9ce7ca9ff3d46736d33653f3ee73e16ef47ac6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
